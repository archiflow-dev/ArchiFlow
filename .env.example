# LLM Provider Configuration
# Set the default LLM provider (openai, anthropic, glm, mock)
DEFAULT_LLM_PROVIDER=glm

# API Keys
OPENAI_API_KEY=<your-openai-api-key>
ANTHROPIC_API_KEY=<your-anthropic-api-key>
ZAI_API_KEY=<your-zai-api-key>
GOOGLE_API_KEY=<your-google-api-key>

# Model Configurations
OPENAI_MODEL=gpt-5
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ZAI_MODEL=glm-4.6

# Optional: Override default models per provider
DEFAULT_OPENAI_MODEL=gpt-4o-mini
DEFAULT_ANTHROPIC_MODEL=claude-3-haiku-20240307
DEFAULT_GLM_MODEL=glm-4.6

# Optional: Custom base URLs for providers
OPENAI_BASE_URL=https://api.openai.com/v1
ANTHROPIC_BASE_URL=https://api.anthropic.com
GLM_BASE_URL=https://api.z.ai/api/coding/paas/v4

# Optional: Override model for specific tools
# PROMPT_REFINER_MODEL=gpt-4o-mini  # Use a faster/cheaper model for prompt refinement

# Agent Behavior Configuration
# ============================================
# Auto-Refinement System (Option 3: Pre-Processing Hook)
# ============================================
# Enable automatic prompt refinement for all agents.
#
# When enabled, a pre-processor runs BEFORE the agent sees any UserMessage:
# - Analyzes prompt quality using PromptRefinerTool
# - If quality < threshold, replaces content with refined version
# - Agent receives refined prompt with ZERO contamination of:
#   * System prompt (remains clean and focused)
#   - Conversation history (no refinement meta-conversation)
#   - Memory/context (only task-relevant content)
#
# Architecture benefits:
# - Single hook point for all UserMessages
# - Easy to enable/disable globally
# - Agent unaware of refinement (clean separation)
#
# Set to "true" to enable, "false" to disable (default)
AUTO_REFINE_PROMPTS=false

# Quality threshold for refinement (0.0 - 10.0)
# Prompts with quality >= this score pass through unchanged
# Prompts with quality < this score get refined automatically
# Default: 9.0 (only refine prompts below excellent quality)
# Options:
#   6.0 = Conservative (only refine very poor prompts)
#   9.0 = Balanced (refine anything below excellent)
#   10.0 = Aggressive (always try to improve)
# AUTO_REFINE_THRESHOLD=9.0

# Minimum message length to consider for refinement
# Messages shorter than this (in characters) are always passed through
# This prevents refinement of short responses like "yes", "no", "ok"
# Default: 10 characters
# AUTO_REFINE_MIN_LENGTH=10

# Search engine configuration
# Set to 'google' or 'duckduckgo' (default: duckduckgo)
WEB_SEARCH_PROVIDER=duckduckgo

# Google Search API configuration (required if WEB_SEARCH_PROVIDER=google)
# To set up Google Search:
# 1. Get API key from Google Cloud Console: https://console.cloud.google.com/
# 2. Create a Programmable Search Engine: https://programmablesearchengine.google.com/
# 3. Add your API key and Search Engine ID below
GOOGLE_SEARCH_API_KEY=<your-google-search-api-key>
GOOGLE_SEARCH_ENGINE_ID=<your-search-engine-id>